## Train Dataset
The evaluation dataset can be found [here](https://www.dropbox.com/t/2Amyu4D5TulaIofv).
And using in (1) `n01440764` - containing **real** images for RealYoutube
             (2) `n01443537` - containing **fake** images for FaceSwap

  % mkdir data/progan_train/images/train/{n01440764, n01443537} \
  % mkdir data/progan_train/images/val/{n01440764, n01443537} \

and put all real .png in n01440764, put all fake .png in n01443537

## Evaluation Dataset
The evaluation dataset can be found [here](https://www.dropbox.com/t/2Amyu4D5TulaIofv).
And using in (1) `n01440764` - containing **real** images for RealYoutube
             (2) `n01443537` - containing **fake** images for NeuralTextures

  % mkdir test_data/progan/images/train/{n01440764, n01443537} \
  % mkdir test_data/progan/images/val/{n01440764, n01443537} \

and put all real .png in n01440764, put all fake .png in n01443537

## Create a result area for output
  % cd ~/CLIPping-the-Deception \
  % mkdir eval_output 
then after run.sh you can get your result in /eval_output

**Important!!** <br />
Download and extract **weights.zip** in the same folder as `evaluate.py`

# Result 
<img width="260" alt="Screenshot 2025-06-24 at 14 11 10" src="https://github.com/user-attachments/assets/1f8c3b7c-e54f-4d4e-bd01-5746b2aa1508" />

# Citations
If you use this code in your research, please kindly cite the following papers:
```
@inproceedings{khan2024clipping,
  title={CLIPping the Deception: Adapting Vision-Language Models for Universal Deepfake Detection},
  author={Khan, Sohail Ahmed and Dang-Nguyen, Duc-Tien},
  booktitle={Proceedings of the 2024 International Conference on Multimedia Retrieval},
  pages={1006--1015},
  year={2024}
}

@inproceedings{zhou2022cocoop,
    title={Conditional Prompt Learning for Vision-Language Models},
    author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}

@article{zhou2022coop,
    title={Learning to Prompt for Vision-Language Models},
    author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
    journal={International Journal of Computer Vision (IJCV)},
    year={2022}
}
```
